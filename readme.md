Modular Vision-Based Multi-task Learning for Eye Disease Diagnosis
1. Project Overview
This project implements a modular, multi-task deep learning system for diagnosing eye diseases from retinal fundus images, as outlined in the "Computer Vision Research Engineer" assignment. The system is designed to perform two primary tasks simultaneously:

Disease Grading Classification: A multi-class classification task to determine the severity of Diabetic Retinopathy (DR) (5 classes, 0-4).

Lesion & Landmark Segmentation: A multi-label segmentation task to identify the location of different types of lesions (Microaneurysms, Haemorrhages, Hard Exudates, Soft Exudates) and the Optic Disc.

The implementation uses PyTorch and follows a modular structure for clarity, maintainability, and extensibility.

Key Features:
Multi-Task Architecture: A single, unified model with a shared encoder backbone and task-specific "expert" heads for classification and segmentation.

Data Preprocessing: A script is provided to unify the disparate dataset sources into a single, cohesive dataset suitable for multi-task training.

Modular Code: The codebase is organized into logical modules for data loading, model architecture, training logic, and utilities.

Comprehensive Training and Evaluation: The project includes scripts for training the model, evaluating its performance on both tasks, and generating visual results.

Reproducibility: The project setup includes a requirements.txt file and uses fixed random seeds to ensure reproducibility.

2. Project Structure
The project is organized into the following directories and files:

vision_multi_task_learning/
│
├── data/
│   └── IDRiD/  # <-- Place the downloaded IDRiD dataset here
│       ├── A. Segmentation/
│       └── B. Disease Grading/
│
├── preprocessed_data/ # (Auto-generated by preprocess_data.py)
│   ├── train_images/
│   ├── test_images/
│   ├── train_masks/
│   └── test_masks/
│   ├── train.csv
│   └── test.csv
│
├── outputs/ # (Auto-generated by train.py)
│   ├── models/
│   └── results/
│
├── runs/ # (Auto-generated by predict.py)
│   └── ... (prediction images will be saved here)
│
├── src/
│   ├── __init__.py
│   ├── config.py             # Configuration file for hyperparameters and paths
│   ├── data_loader.py        # PyTorch Dataset and DataLoader
│   ├── engine.py             # Training and evaluation loops
│   ├── model.py              # The multi-task model architecture
│   └── utils.py              # Helper functions (metrics, logging, etc.)
│
├── preprocess_data.py        # Script to merge and preprocess the raw dataset
├── train.py                  # Main script to start model training
├── evaluate.py               # Script to evaluate a trained model
├── predict.py                # Script to run prediction on a single image
│
├── README.md                 # This file
├── report.md                 # Project report explaining design and results
└── requirements.txt          # Python dependencies

3. Getting Started
3.1. Prerequisites
Python 3.8+

PyTorch

CUDA-enabled GPU (highly recommended for training)

3.2. Installation
Clone the repository:

git clone <repository_url>
cd vision_multi_task_learning

Install the required dependencies:

pip install -r requirements.txt

3.3. Dataset Setup
Download the IDRiD Dataset: Obtain the dataset from the official IDRiD website.

Organize the Dataset: Unzip and place the dataset into the data/IDRiD directory, maintaining the original structure.

data/
└── IDRiD/
    ├── A. Segmentation/
    └── B. Disease Grading/

Run the Preprocessing Script: This is a mandatory first step. The script unifies the separate segmentation and classification datasets into a single format that the multi-task data loader can use.

python preprocess_data.py

This will create a preprocessed_data directory containing the processed images, combined masks, and two CSV files (train.csv and test.csv).

4. Usage
4.1. Training the Model
To start the training process, run the train.py script:

python train.py

The script loads configurations from src/config.py.

Training progress, including loss and performance metrics for each task, will be printed to the console.

The best model (based on validation performance) will be saved in the outputs/models/ directory.

A log file with the training history will be saved in the outputs/ directory.

4.2. Evaluating the Model
To evaluate the trained model on the entire test set, run the evaluate.py script:

python evaluate.py --model_path outputs/models/best_model.pth

The script will load the specified model.

It computes and displays the final performance metrics (Accuracy, Dice Score, IoU) on the test set.

It saves visual examples of the model's predictions in the outputs/results/ directory.

4.3. Making a Single Prediction
To run inference on a single image file with your trained model, use the predict.py script.

python predict.py --image /path/to/your/image.jpg

--image: (Required) The path to the input image you want to test.

--model_path: (Optional) The path to the trained .pth model file. It defaults to the best_model.pth saved during training.

The script will generate an output image showing the original input side-by-side with the predicted segmentation mask overlay. The predicted disease grade and confidence score will be in the title. The output is saved inside the runs/ directory.